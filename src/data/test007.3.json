{
  "pass_percent": 70,
  "questions": [
    {
      "_class": "assessment",
      "id": 113402000,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has hundreds of Amazon EC2 Linux-based instances in the AWS Cloud. Systems administrators have used shared SSH keys to manage the instances. After a recent audit, the company’s security team is mandating the removal of all shared keys. A solutions architect must design a solution that provides secure access to the EC2 instances. Which solution will meet this requirement with the LEAST amount of administrative overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Use AWS Systems Manager Session Manager to connect to the EC2 instances.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use AWS Systems Manager Session Manager to connect to the EC2 instances.</p>",
          "<p>B. Use AWS Security Token Service (AWS STS) to generate one-time SSH keys on demand.</p>",
          "<p>C. Allow shared SSH access to a set of bastion instances. Configure all other instances to allow only SSH access from the bastion instances.</p>",
          "<p>D. Use an Amazon Cognito custom authorizer to authenticate users. Invoke an AWS Lambda function to generate a temporary SSH key.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has hundreds of Amazon EC2 Linux-based instances in the AWS Cloud. Systems administrators have used shared SSH keys to manage the instances. After a recent audit, the company’s security team is mandating the removal of all shared keys. A solutions architect must design a solution that provides secure access to the EC2 instances. Which solution will meet this requirement with the LEAST amount of administrative overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402001,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is using a fleet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-flight is lost. The company’s data science team wants to query ingested data in near-real time. Which solution provides near-real-time data querying that is scalable with minimal data loss?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Publish data to Amazon Kinesis Data Streams, Use Kinesis Data Analytics to query the data.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Publish data to Amazon Kinesis Data Streams, Use Kinesis Data Analytics to query the data.</p>",
          "<p>B. Publish data to Amazon Kinesis Data Firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data.</p>",
          "<p>C. Store ingested data in an EC2 instance store. Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data.</p>",
          "<p>D. Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is using a fleet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-flight is lost. The company’s data science team wants to query ingested data in near-real time. Which solution provides near-real-time data querying that is scalable with minimal data loss?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402002,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>What should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set.</p>",
          "<p>B. Update the bucket policy to deny if the PutObject does not have an s3:x-amz-acl header set to private.</p>",
          "<p>C. Update the bucket policy to deny if the PutObject does not have an aws:SecureTransport header set to true.</p>",
          "<p>D. Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "What should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402003,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A solutions architect is designing a multi-tier application for a company. The application's users upload images from a mobile device. The application generates a thumbnail of each image and returns a message to the user to confirm that the image was uploaded successfully. The thumbnail generation can take up to 60 seconds, but the company wants to provide a faster response time to its users to notify them that the original image was received. The solutions architect must design the application to asynchronously dispatch requests to the different application tiers. What should the solutions architect do to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Create an Amazon Simple Queue Service (Amazon SQS) message queue. As images are uploaded, place a message on the SQS queue for thumbnail generation. Alert the user through an application message that the image was received.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Write a custom AWS Lambda function to generate the thumbnail and alert the user. Use the image upload process as an event source to invoke the Lambda function.</p>",
          "<p>B. Create an AWS Step Functions workflow. Configure Step Functions to handle the orchestration between the application tiers and alert the user when thumbnail generation is complete.</p>",
          "<p>C. Create an Amazon Simple Queue Service (Amazon SQS) message queue. As images are uploaded, place a message on the SQS queue for thumbnail generation. Alert the user through an application message that the image was received.</p>",
          "<p>D. Create Amazon Simple Notification Service (Amazon SNS) notification topics and subscriptions. Use one subscription with the application to generate the thumbnail after the image upload is complete. Use a second subscription to message the user's mobile app by way of a push notification after thumbnail generation is complete.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A solutions architect is designing a multi-tier application for a company. The application's users upload images from a mobile device. The application generates a thumbnail of each image and returns a message to the user to confirm that the image was uploaded successfully. The thumbnail generation can take up to 60 seconds, but the company wants to provide a faster response time to its users to notify them that the original image was received. The solutions architect must design the application to asynchronously dispatch requests to the different application tiers. What should the solutions architect do to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402004,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company’s facility has badge readers at every entrance throughout the building. When badges are scanned, the readers send a message over HTTPS to indicate who attempted to access that particular entrance. A solutions architect must design a system to process these messages from the sensors. The solution must be highly available, and the results must be made available for the company’s security team to analyze. Which system architecture should the solutions architect recommend?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Launch an Amazon EC2 instance to serve as the HTTPS endpoint and to process the messages. Configure the EC2 instance to save the results to an Amazon S3 bucket.</p>",
          "<p>B. Create an HTTPS endpoint in Amazon API Gateway. Configure the API Gateway endpoint to invoke an AWS Lambda function to process the messages and save the results to an Amazon DynamoDB table.</p>",
          "<p>C. Use Amazon Route 53 to direct incoming sensor messages to an AWS Lambda function. Configure the Lambda function to process the messages and save the results to an Amazon DynamoDB table.</p>",
          "<p>D. Create a gateway VPC endpoint for Amazon S3. Configure a Site-to-Site VPN connection from the facility network to the VPC so that sensor data can be written directly to an S3 bucket by way of the VPC endpoint.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company’s facility has badge readers at every entrance throughout the building. When badges are scanned, the readers send a message over HTTPS to indicate who attempted to access that particular entrance. A solutions architect must design a system to process these messages from the sensors. The solution must be highly available, and the results must be made available for the company’s security team to analyze. Which system architecture should the solutions architect recommend?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402005,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company wants to implement a disaster recovery plan for its primary on-premises file storage volume. The file storage volume is mounted from an Internet Small Computer Systems Interface (iSCSI) device on a local storage server. The file storage volume holds hundreds of terabytes (TB) of data. The company wants to ensure that end users retain immediate access to all file types from the on-premises systems without experiencing latency. Which solution will meet these requirements with the LEAST amount of change to the company's existing infrastructure?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Provision an AWS Storage Gateway Volume Gateway cached volume. Set the local cache to 10 TB. Mount the Volume Gateway cached volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Provision an Amazon S3 File Gateway as a virtual machine (VM) that is hosted on premises. Set the local cache to 10 TB. Modify existing applications to access the files through the NFS protocol. To recover from a disaster, provision an Amazon EC2 instance and mount the S3 bucket that contains the files.</p>",
          "<p>B. Provision an AWS Storage Gateway tape gateway. Use a data backup solution to back up all existing data to a virtual tape library. Configure the data backup solution to run nightly after the initial backup is complete. To recover from a disaster, provision an Amazon EC2 instance and restore the data to an Amazon Elastic Block Store (Amazon EBS) volume from the volumes in the virtual tape library.</p>",
          "<p>C. Provision an AWS Storage Gateway Volume Gateway cached volume. Set the local cache to 10 TB. Mount the Volume Gateway cached volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.</p>",
          "<p>D. Provision an AWS Storage Gateway Volume Gateway stored volume with the same amount of disk space as the existing file storage volume. Mount the Volume Gateway stored volume to the existing file server by using iSCSI, and copy all files to the storage volume. Configure scheduled snapshots of the storage volume. To recover from a disaster, restore a snapshot to an Amazon Elastic Block Store (Amazon EBS) volume and attach the EBS volume to an Amazon EC2 instance.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company wants to implement a disaster recovery plan for its primary on-premises file storage volume. The file storage volume is mounted from an Internet Small Computer Systems Interface (iSCSI) device on a local storage server. The file storage volume holds hundreds of terabytes (TB) of data. The company wants to ensure that end users retain immediate access to all file types from the on-premises systems without experiencing latency. Which solution will meet these requirements with the LEAST amount of change to the company's existing infrastructure?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402006,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is hosting a web application from an Amazon S3 bucket. The application uses Amazon Cognito as an identity provider to authenticate users and return a JSON Web Token (JWT) that provides access to protected resources that are stored in another S3 bucket. Upon deployment of the application, users report errors and are unable to access the protected content. A solutions architect must resolve this issue by providing proper permissions so that users can access the protected content. Which solution meets these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Update the Amazon Cognito identity pool to assume the proper IAM role for access to the protected content.</p>",
          "<p>B. Update the S3 ACL to allow the application to access the protected content.</p>",
          "<p>C. Redeploy the application to Amazon S3 to prevent eventually consistent reads in the S3 bucket from affecting the ability of users to access the protected content.</p>",
          "<p>D. Update the Amazon Cognito pool to use custom attribute mappings within the identity pool and grant users the proper permissions to access the protected content.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is hosting a web application from an Amazon S3 bucket. The application uses Amazon Cognito as an identity provider to authenticate users and return a JSON Web Token (JWT) that provides access to protected resources that are stored in another S3 bucket. Upon deployment of the application, users report errors and are unable to access the protected content. A solutions architect must resolve this issue by providing proper permissions so that users can access the protected content. Which solution meets these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402007,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>An image hosting company uploads its large assets to Amazon S3 Standard buckets. The company uses multipart upload in parallel by using S3 APIs and overwrites if the same object is uploaded again. For the first 30 days after upload, the objects will be accessed frequently. The objects will be used less frequently after 30 days, but the access patterns for each object will be inconsistent. The company must optimize its S3 storage costs while maintaining high availability and resiliency of stored assets. Which combination of actions should a solutions architect recommend to meet these requirements? (Choose two.)</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Move assets to S3 Intelligent-Tiering after 30 days.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Move assets to S3 Intelligent-Tiering after 30 days.</p>",
          "<p>B. Configure an S3 Lifecycle policy to clean up incomplete multipart uploads.</p>",
          "<p>C. Configure an S3 Lifecycle policy to clean up expired object delete markers.</p>",
          "<p>D. Move assets to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days. E. Move assets to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "An image hosting company uploads its large assets to Amazon S3 Standard buckets. The company uses multipart upload in parallel by using S3 APIs and overwrites if the same object is uploaded again. For the first 30 days after upload, the objects will be accessed frequently. The objects will be used less frequently after 30 days, but the access patterns for each object will be inconsistent. The company must optimize its S3 storage costs while maintaining high availability and resiliency of stored assets. Which combination of actions should a solutions architect recommend to meet these requirements? (Choose two.)",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402008,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is hosting a three-tier ecommerce application in the AWS Cloud. The company hosts the website on Amazon S3 and integrates the website with an API that handles sales requests. The company hosts the API on three Amazon EC2 instances behind an Application Load Balancer (ALB). The API consists of static and dynamic front-end content along with backend workers that process sales requests asynchronously. The company is expecting a significant and sudden increase in the number of sales requests during events for the launch of new products. What should a solutions architect recommend to ensure that all the requests are processed successfully?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Add an Amazon CloudFront distribution for the static content. Place the EC2 instances in an Auto Scaling group to launch new instances based on network traffic.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Add an Amazon CloudFront distribution for the dynamic content. Increase the number of EC2 instances to handle the increase in traffic.</p>",
          "<p>B. Add an Amazon CloudFront distribution for the static content. Place the EC2 instances in an Auto Scaling group to launch new instances based on network traffic.</p>",
          "<p>C. Add an Amazon CloudFront distribution for the dynamic content. Add an Amazon ElastiCache instance in front of the ALB to reduce traffic for the API to handle.</p>",
          "<p>D. Add an Amazon CloudFront distribution for the static content. Add an Amazon Simple Queue Service (Amazon SQS) queue to receive requests from the website for later processing by the EC2 instances.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is hosting a three-tier ecommerce application in the AWS Cloud. The company hosts the website on Amazon S3 and integrates the website with an API that handles sales requests. The company hosts the API on three Amazon EC2 instances behind an Application Load Balancer (ALB). The API consists of static and dynamic front-end content along with backend workers that process sales requests asynchronously. The company is expecting a significant and sudden increase in the number of sales requests during events for the launch of new products. What should a solutions architect recommend to ensure that all the requests are processed successfully?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402009,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A security audit reveals that Amazon EC2 instances are not being patched regularly. A solutions architect needs to provide a solution that will run regular security scans across a large fleet of EC2 instances. The solution should also patch the EC2 instances on a regular schedule and provide a report of each instance’s patch status. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Turn on Amazon Inspector in the account. Configure Amazon Inspector to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Patch Manager to patch the EC2 instances on a regular schedule.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Set up Amazon Macie to scan the EC2 instances for software vulnerabilities. Set up a cron job on each EC2 instance to patch the instance on a regular schedule.</p>",
          "<p>B. Turn on Amazon GuardDuty in the account. Configure GuardDuty to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Session Manager to patch the EC2 instances on a regular schedule.</p>",
          "<p>C. Set up Amazon Detective to scan the EC2 instances for software vulnerabilities. Set up an Amazon EventBridge scheduled rule to patch the EC2 instances on a regular schedule.</p>",
          "<p>D. Turn on Amazon Inspector in the account. Configure Amazon Inspector to scan the EC2 instances for software vulnerabilities. Set up AWS Systems Manager Patch Manager to patch the EC2 instances on a regular schedule.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A security audit reveals that Amazon EC2 instances are not being patched regularly. A solutions architect needs to provide a solution that will run regular security scans across a large fleet of EC2 instances. The solution should also patch the EC2 instances on a regular schedule and provide a report of each instance’s patch status. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402010,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is planning to store data on Amazon RDS DB instances. The company must encrypt the data at rest. What should a solutions architect do to meet this requirement?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Create a key in AWS Key Management Service (AWS KMS). Enable encryption for the DB instances.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create a key in AWS Key Management Service (AWS KMS). Enable encryption for the DB instances.</p>",
          "<p>B. Create an encryption key. Store the key in AWS Secrets Manager. Use the key to encrypt the DB instances.</p>",
          "<p>C. Generate a certificate in AWS Certificate Manager (ACM). Enable SSL/TLS on the DB instances by using the certificate.</p>",
          "<p>D. Generate a certificate in AWS Identity and Access Management (IAM). Enable SSL/TLS on the DB instances by using the certificate.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is planning to store data on Amazon RDS DB instances. The company must encrypt the data at rest. What should a solutions architect do to meet this requirement?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402011,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company’s network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Use AWS Snowball.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use AWS Snowball.</p>",
          "<p>B. Use AWS DataSync.</p>",
          "<p>C. Use a secure VPN connection.</p>",
          "<p>D. Use Amazon S3 Transfer Acceleration.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company’s network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402012,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees’ devices. The files are stored in an on-premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity. . Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on-premises Active Directory. Configure AWS Client VPN.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Migrate the file server to an Amazon EC2 instance in a public subnet. Configure the security group to limit inbound traffic to the employees’ IP addresses.</p>",
          "<p>B. Migrate the files to an Amazon FSx for Windows File Server file system. Integrate the Amazon FSx file system with the on-premises Active Directory. Configure AWS Client VPN.</p>",
          "<p>C. Migrate the files to Amazon S3, and create a private VPC endpoint. Create a signed URL to allow download.</p>",
          "<p>D. Migrate the files to Amazon S3, and create a public VPC endpoint. Allow employees to sign on with AWS IAM Identity Center (AWS Single Sign-On).</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company needs to provide its employees with secure access to confidential and sensitive files. The company wants to ensure that the files can be accessed only by authorized users. The files must be downloaded securely to the employees’ devices. The files are stored in an on-premises Windows file server. However, due to an increase in remote usage, the file server is running out of capacity. . Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402013,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company’s application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month-end financial calculation batch runs. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application. What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Configure an Amazon CloudFront distribution in front of the ALB.</p>",
          "<p>B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization.</p>",
          "<p>C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule.</p>",
          "<p>D. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company’s application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. On the first day of every month at midnight, the application becomes much slower when the month-end financial calculation batch runs. This causes the CPU utilization of the EC2 instances to immediately peak to 100%, which disrupts the application. What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402014,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company wants to give a customer the ability to use on-premises Microsoft Active Directory to download files that are stored in Amazon S3. The customer’s application uses an SFTP client to download the files. Which solution will meet these requirements with the LEAST operational overhead and no changes to the customer’s application?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Set up AWS Transfer Family with SFTP for Amazon S3. Configure integrated Active Directory authentication.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Set up AWS Transfer Family with SFTP for Amazon S3. Configure integrated Active Directory authentication.</p>",
          "<p>B. Set up AWS Database Migration Service (AWS DMS) to synchronize the on-premises client with Amazon S3. Configure integrated Active Directory authentication.</p>",
          "<p>C. Set up AWS DataSync to synchronize between the on-premises location and the S3 location by using AWS IAM Identity Center (AWS Single Sign-On).</p>",
          "<p>D. Set up a Windows Amazon EC2 instance with SFTP to connect the on-premises client with Amazon S3. Integrate AWS Identity and Access Management (IAM).</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company wants to give a customer the ability to use on-premises Microsoft Active Directory to download files that are stored in Amazon S3. The customer’s application uses an SFTP client to download the files. Which solution will meet these requirements with the LEAST operational overhead and no changes to the customer’s application?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402015,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is experiencing sudden increases in demand. The company needs to provision large Amazon EC2 instances from an Amazon Machine Image (AMI). The instances will run in an Auto Scaling group. The company needs a solution that provides minimum initialization latency to meet the demand. Which solution meets these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Enable Amazon Elastic Block Store (Amazon EBS) fast snapshot restore on a snapshot. Provision an AMI by using the snapshot. Replace the AMI in the Auto Scaling group with the new AMI.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use the aws ec2 register-image command to create an AMI from a snapshot. Use AWS Step Functions to replace the AMI in the Auto Scaling group.</p>",
          "<p>B. Enable Amazon Elastic Block Store (Amazon EBS) fast snapshot restore on a snapshot. Provision an AMI by using the snapshot. Replace the AMI in the Auto Scaling group with the new AMI.</p>",
          "<p>C. Enable AMI creation and define lifecycle rules in Amazon Data Lifecycle Manager (Amazon DLM). Create an AWS Lambda function that modifies the AMI in the Auto Scaling group.</p>",
          "<p>D. Use Amazon EventBridge to invoke AWS Backup lifecycle policies that provision AMIs. Configure Auto Scaling group capacity limits as an event source in EventBridge.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is experiencing sudden increases in demand. The company needs to provision large Amazon EC2 instances from an Amazon Machine Image (AMI). The instances will run in an Auto Scaling group. The company needs a solution that provides minimum initialization latency to meet the demand. Which solution meets these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402016,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company hosts a multi-tier web application that uses an Amazon Aurora MySQL DB cluster for storage. The application tier is hosted on Amazon EC2 instances. The company’s IT security guidelines mandate that the database credentials be encrypted and rotated every 14 days. What should a solutions architect do to meet this requirement with the LEAST operational effort?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create a new AWS Key Management Service (AWS KMS) encryption key. Use AWS Secrets Manager to create a new secret that uses the KMS key with the appropriate credentials. Associate the secret with the Aurora DB cluster. Configure a custom rotation period of 14 days.</p>",
          "<p>B. Create two parameters in AWS Systems Manager Parameter Store: one for the user name as a string parameter and one that uses the SecureString type for the password. Select AWS Key Management Service (AWS KMS) encryption for the password parameter, and load these parameters in the application tier. Implement an AWS Lambda function that rotates the password every 14 days.</p>",
          "<p>C. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in all EC2 instances of the application tier. Restrict the access to the file on the file system so that the application can read the file and that only super users can modify the file. Implement an AWS Lambda function that rotates the key in Aurora every 14 days and writes new credentials into the file.</p>",
          "<p>D. Store a file that contains the credentials in an AWS Key Management Service (AWS KMS) encrypted Amazon S3 bucket that the application uses to load the credentials. Download the file to the application regularly to ensure that the correct credentials are used. Implement an AWS Lambda function that rotates the Aurora credentials every 14 days and uploads these credentials to the file in the S3 bucket.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company hosts a multi-tier web application that uses an Amazon Aurora MySQL DB cluster for storage. The application tier is hosted on Amazon EC2 instances. The company’s IT security guidelines mandate that the database credentials be encrypted and rotated every 14 days. What should a solutions architect do to meet this requirement with the LEAST operational effort?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402017,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has deployed a web application on AWS. The company hosts the backend database on Amazon RDS for MySQL with a primary DB instance and five read replicas to support scaling needs. The read replicas must lag no more than 1 second behind the primary DB instance. The database routinely runs scheduled stored procedures. As traffic on the website increases, the replicas experience additional lag during periods of peak load. A solutions architect must reduce the replication lag as much as possible. The solutions architect must minimize changes to the application code and must minimize ongoing operational overhead. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Migrate the database to Amazon Aurora MySQL. Replace the read replicas with Aurora Replicas, and configure Aurora Auto Scaling. Replace the stored procedures with Aurora MySQL native functions.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Migrate the database to Amazon Aurora MySQL. Replace the read replicas with Aurora Replicas, and configure Aurora Auto Scaling. Replace the stored procedures with Aurora MySQL native functions.</p>",
          "<p>B. Deploy an Amazon ElastiCache for Redis cluster in front of the database. Modify the application to check the cache before the application queries the database. Replace the stored procedures with AWS Lambda functions.</p>",
          "<p>C. Migrate the database to a MySQL database that runs on Amazon EC2 instances. Choose large, compute optimized EC2 instances for all replica nodes. Maintain the stored procedures on the EC2 instances.</p>",
          "<p>D. Migrate the database to Amazon DynamoDB. Provision a large number of read capacity units (RCUs) to support the required throughput, and configure on-demand capacity scaling. Replace the stored procedures with DynamoDB streams.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has deployed a web application on AWS. The company hosts the backend database on Amazon RDS for MySQL with a primary DB instance and five read replicas to support scaling needs. The read replicas must lag no more than 1 second behind the primary DB instance. The database routinely runs scheduled stored procedures. As traffic on the website increases, the replicas experience additional lag during periods of peak load. A solutions architect must reduce the replication lag as much as possible. The solutions architect must minimize changes to the application code and must minimize ongoing operational overhead. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402018,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A solutions architect must create a disaster recovery (DR) plan for a high-volume software as a service (SaaS) platform. All data for the platform is stored in an Amazon Aurora MySQL DB cluster. The DR plan must replicate data to a secondary AWS Region. Which solution will meet these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use MySQL binary log replication to an Aurora cluster in the secondary Region. Provision one DB instance for the Aurora cluster in the secondary Region.</p>",
          "<p>B. Set up an Aurora global database for the DB cluster. When setup is complete, remove the DB instance from the secondary Region.</p>",
          "<p>C. Use AWS Database Migration Service (AWS DMS) to continuously replicate data to an Aurora cluster in the secondary Region. Remove the DB instance from the secondary Region.</p>",
          "<p>D. Set up an Aurora global database for the DB cluster. Specify a minimum of one DB instance in the secondary Region.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A solutions architect must create a disaster recovery (DR) plan for a high-volume software as a service (SaaS) platform. All data for the platform is stored in an Amazon Aurora MySQL DB cluster. The DR plan must replicate data to a secondary AWS Region. Which solution will meet these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402019,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort. What should a solutions architect do to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use AWS Key Management Service (AWS KMS) to create keys. Configure the application to load the database credentials from AWS KMS. Enable automatic key rotation.</p>",
          "<p>B. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secret Manager.</p>",
          "<p>C. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager.</p>",
          "<p>D. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort. What should a solutions architect do to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402020,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A media company hosts its website on AWS. The website application’s architecture includes a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB) and a database that is hosted on Amazon Aurora. The company’s cybersecurity team reports that the application is vulnerable to SQL injection. How should the company resolve this issue?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Use AWS WAF in front of the ALB. Associate the appropriate web ACLs with AWS WAF.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use AWS WAF in front of the ALB. Associate the appropriate web ACLs with AWS WAF.</p>",
          "<p>B. Create an ALB listener rule to reply to SQL injections with a fixed response.</p>",
          "<p>C. Subscribe to AWS Shield Advanced to block all SQL injection attempts automatically.</p>",
          "<p>D. Set up Amazon Inspector to block all SQL injection attempts automatically.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A media company hosts its website on AWS. The website application’s architecture includes a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB) and a database that is hosted on Amazon Aurora. The company’s cybersecurity team reports that the application is vulnerable to SQL injection. How should the company resolve this issue?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402021,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A transaction processing company has weekly scripted batch jobs that run on Amazon EC2 instances. The EC2 instances are in an Auto Scaling group. The number of transactions can vary, but the baseline CPU utilization that is noted on each run is at least 60%. The company needs to provision the capacity 30 minutes before the jobs run. Currently, engineers complete this task by manually modifying the Auto Scaling group parameters. The company does not have the resources to analyze the required capacity trends for the Auto Scaling group counts. The company needs an automated way to modify the Auto Scaling group’s desired capacity. Which solution will meet these requirements with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Create a predictive scaling policy for the Auto Scaling group. Configure the policy to scale based on forecast. Set the scaling metric to CPU utilization. Set the target value for the metric to 60%. In the policy, set the instances to pre-launch 30 minutes before the jobs run.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create a dynamic scaling policy for the Auto Scaling group. Configure the policy to scale based on the CPU utilization metric. Set the target value for the metric to 60%.</p>",
          "<p>B. Create a scheduled scaling policy for the Auto Scaling group. Set the appropriate desired capacity, minimum capacity, and maximum capacity. Set the recurrence to weekly. Set the start time to 30 minutes before the batch jobs run.</p>",
          "<p>C. Create a predictive scaling policy for the Auto Scaling group. Configure the policy to scale based on forecast. Set the scaling metric to CPU utilization. Set the target value for the metric to 60%. In the policy, set the instances to pre-launch 30 minutes before the jobs run.</p>",
          "<p>D. Create an Amazon EventBridge event to invoke an AWS Lambda function when the CPU utilization metric value for the Auto Scaling group reaches 60%. Configure the Lambda function to increase the Auto Scaling group’s desired capacity and maximum capacity by 20%.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A transaction processing company has weekly scripted batch jobs that run on Amazon EC2 instances. The EC2 instances are in an Auto Scaling group. The number of transactions can vary, but the baseline CPU utilization that is noted on each run is at least 60%. The company needs to provision the capacity 30 minutes before the jobs run. Currently, engineers complete this task by manually modifying the Auto Scaling group parameters. The company does not have the resources to analyze the required capacity trends for the Auto Scaling group counts. The company needs an automated way to modify the Auto Scaling group’s desired capacity. Which solution will meet these requirements with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402022,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A solutions architect is designing a company’s disaster recovery (DR) architecture. The company has a MySQL database that runs on an Amazon EC2 instance in a private subnet with scheduled backup. The DR design needs to include multiple AWS Regions. Which solution will meet these requirements with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Migrate the MySQL database to an Amazon Aurora global database. Host the primary DB cluster in the primary Region. Host the secondary DB cluster in the DR Region.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Migrate the MySQL database to multiple EC2 instances. Configure a standby EC2 instance in the DR Region. Turn on replication.</p>",
          "<p>B. Migrate the MySQL database to Amazon RDS. Use a Multi-AZ deployment. Turn on read replication for the primary DB instance in the different Availability Zones.</p>",
          "<p>C. Migrate the MySQL database to an Amazon Aurora global database. Host the primary DB cluster in the primary Region. Host the secondary DB cluster in the DR Region.</p>",
          "<p>D. Store the scheduled backup of the MySQL database in an Amazon S3 bucket that is configured for S3 Cross-Region Replication (CRR). Use the data backup to restore the database in the DR Region.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A solutions architect is designing a company’s disaster recovery (DR) architecture. The company has a MySQL database that runs on an Amazon EC2 instance in a private subnet with scheduled backup. The DR design needs to include multiple AWS Regions. Which solution will meet these requirements with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402023,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has a Java application that uses Amazon Simple Queue Service (Amazon SQS) to parse messages. The application cannot parse messages that are larger than 256 KB in size. The company wants to implement a solution to give the application the ability to parse messages as large as 50 MB. Which solution will meet these requirements with the FEWEST changes to the code?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Use the Amazon SQS Extended Client Library for Java to host messages that are larger than 256 KB in Amazon S3.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use the Amazon SQS Extended Client Library for Java to host messages that are larger than 256 KB in Amazon S3.</p>",
          "<p>B. Use Amazon EventBridge to post large messages from the application instead of Amazon SQS.</p>",
          "<p>C. Change the limit in Amazon SQS to handle messages that are larger than 256 KB.</p>",
          "<p>D. Store messages that are larger than 256 KB in Amazon Elastic File System (Amazon EFS). Configure Amazon SQS to reference this location in the messages.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has a Java application that uses Amazon Simple Queue Service (Amazon SQS) to parse messages. The application cannot parse messages that are larger than 256 KB in size. The company wants to implement a solution to give the application the ability to parse messages as large as 50 MB. Which solution will meet these requirements with the FEWEST changes to the code?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402024,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company wants to restrict access to the content of one of its main web applications and to protect the content by using authorization techniques available on AWS. The company wants to implement a serverless architecture and an authentication solution for fewer than 100 users. The solution needs to integrate with the main web application and serve web content globally. The solution must also scale as the company's user base grows while providing the lowest login latency possible. Which solution will meet these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Use Amazon Cognito for authentication. Use Lambda@Edge for authorization. Use Amazon CloudFront to serve the web application globally.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use Amazon Cognito for authentication. Use Lambda@Edge for authorization. Use Amazon CloudFront to serve the web application globally.</p>",
          "<p>B. Use AWS Directory Service for Microsoft Active Directory for authentication. Use AWS Lambda for authorization. Use an Application Load Balancer to serve the web application globally.</p>",
          "<p>C. Use Amazon Cognito for authentication. Use AWS Lambda for authorization. Use Amazon S3 Transfer Acceleration to serve the web application globally.</p>",
          "<p>D. Use AWS Directory Service for Microsoft Active Directory for authentication. Use Lambda@Edge for authorization. Use AWS Elastic Beanstalk to serve the web application globally.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company wants to restrict access to the content of one of its main web applications and to protect the content by using authorization techniques available on AWS. The company wants to implement a serverless architecture and an authentication solution for fewer than 100 users. The solution needs to integrate with the main web application and serve web content globally. The solution must also scale as the company's user base grows while providing the lowest login latency possible. Which solution will meet these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402025,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has an aging network-attached storage (NAS) array in its data center. The NAS array presents SMB shares and NFS shares to client workstations. The company does not want to purchase a new NAS array. The company also does not want to incur the cost of renewing the NAS array’s support contract. Some of the data is accessed frequently, but much of the data is inactive. A solutions architect needs to implement a solution that migrates the data to Amazon S3, uses S3 Lifecycle policies, and maintains the same look and feel for the client workstations. The solutions architect has identified AWS Storage Gateway as part of the solution. Which type of storage gateway should the solutions architect provision to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Amazon S3 File Gateway</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Volume Gateway</p>",
          "<p>B. Tape Gateway</p>",
          "<p>C. Amazon FSx File Gateway</p>",
          "<p>D. Amazon S3 File Gateway</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has an aging network-attached storage (NAS) array in its data center. The NAS array presents SMB shares and NFS shares to client workstations. The company does not want to purchase a new NAS array. The company also does not want to incur the cost of renewing the NAS array’s support contract. Some of the data is accessed frequently, but much of the data is inactive. A solutions architect needs to implement a solution that migrates the data to Amazon S3, uses S3 Lifecycle policies, and maintains the same look and feel for the client workstations. The solutions architect has identified AWS Storage Gateway as part of the solution. Which type of storage gateway should the solutions architect provision to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402026,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has an application that is running on Amazon EC2 instances. A solutions architect has standardized the company on a particular instance family and various instance sizes based on the current needs of the company. The company wants to maximize cost savings for the application over the next 3 years. The company needs to be able to change the instance family and sizes in the next 6 months based on application popularity and usage. Which solution will meet these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Compute Savings Plan</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Compute Savings Plan</p>",
          "<p>B. EC2 Instance Savings Plan</p>",
          "<p>C. Zonal Reserved Instances</p>",
          "<p>D. Standard Reserved Instances</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has an application that is running on Amazon EC2 instances. A solutions architect has standardized the company on a particular instance family and various instance sizes based on the current needs of the company. The company wants to maximize cost savings for the application over the next 3 years. The company needs to be able to change the instance family and sizes in the next 6 months based on application popularity and usage. Which solution will meet these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402027,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company collects data from a large number of participants who use wearable devices. The company stores the data in an Amazon DynamoDB table and uses applications to analyze the data. The data workload is constant and predictable. The company wants to stay at or below its forecasted budget for DynamoDB. Which solution will meet these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs).</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use provisioned mode and DynamoDB Standard-Infrequent Access (DynamoDB Standard-IA). Reserve capacity for the forecasted workload.</p>",
          "<p>B. Use provisioned mode. Specify the read capacity units (RCUs) and write capacity units (WCUs).</p>",
          "<p>C. Use on-demand mode. Set the read capacity units (RCUs) and write capacity units (WCUs) high enough to accommodate changes in the workload.</p>",
          "<p>D. Use on-demand mode. Specify the read capacity units (RCUs) and write capacity units (WCUs) with reserved capacity.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company collects data from a large number of participants who use wearable devices. The company stores the data in an Amazon DynamoDB table and uses applications to analyze the data. The data workload is constant and predictable. The company wants to stay at or below its forecasted budget for DynamoDB. Which solution will meet these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402028,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company stores confidential data in an Amazon Aurora PostgreSQL database in the ap-southeast-3 Region. The database is encrypted with an AWS Key Management Service (AWS KMS) customer managed key. The company was recently acquired and must securely share a backup of the database with the acquiring company’s AWS account in ap-southeast-3. What should a solutions architect do to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Create a database snapshot. Add the acquiring company’s AWS account to the KMS key policy. Share the snapshot with the acquiring company’s AWS account.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create a database snapshot. Copy the snapshot to a new unencrypted snapshot. Share the new snapshot with the acquiring company’s AWS account.</p>",
          "<p>B. Create a database snapshot. Add the acquiring company’s AWS account to the KMS key policy. Share the snapshot with the acquiring company’s AWS account.</p>",
          "<p>C. Create a database snapshot that uses a different AWS managed KMS key. Add the acquiring company’s AWS account to the KMS key alias. Share the snapshot with the acquiring company's AWS account.</p>",
          "<p>D. Create a database snapshot. Download the database snapshot. Upload the database snapshot to an Amazon S3 bucket. Update the S3 bucket policy to allow access from the acquiring company’s AWS account.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company stores confidential data in an Amazon Aurora PostgreSQL database in the ap-southeast-3 Region. The database is encrypted with an AWS Key Management Service (AWS KMS) customer managed key. The company was recently acquired and must securely share a backup of the database with the acquiring company’s AWS account in ap-southeast-3. What should a solutions architect do to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402029,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company uses a 100 GB Amazon RDS for Microsoft SQL Server Single-AZ DB instance in the us-east-1 Region to store customer transactions. The company needs high availability and automatic recovery for the DB instance. The company must also run reports on the RDS database several times a year. The report process causes transactions to take longer than usual to post to the customers’ accounts. The company needs a solution that will improve the performance of the report process. Which combination of steps will meet these requirements? (Choose two.)</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Modify the DB instance from a Single-AZ DB instance to a Multi-AZ deployment:</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Modify the DB instance from a Single-AZ DB instance to a Multi-AZ deployment.</p>",
          "<p>B. Take a snapshot of the current DB instance. Restore the snapshot to a new RDS deployment in another Availability Zone.</p>",
          "<p>C. Create a read replica of the DB instance in a different Availability Zone. Point all requests for reports to the read replica.</p>",
          "<p>D. Migrate the database to RDS Custom. E. Use RDS Proxy to limit reporting requests to the maintenance window.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company uses a 100 GB Amazon RDS for Microsoft SQL Server Single-AZ DB instance in the us-east-1 Region to store customer transactions. The company needs high availability and automatic recovery for the DB instance. The company must also run reports on the RDS database several times a year. The report process causes transactions to take longer than usual to post to the customers’ accounts. The company needs a solution that will improve the performance of the report process. Which combination of steps will meet these requirements? (Choose two.)",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402030,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture. The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workflow. The company also wants to minimize operational overhead. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Build out the workflow in AWS Glue. Use AWS Glue to invoke AWS Lambda functions to process the workflow steps.</p>",
          "<p>B. Build out the workflow in AWS Step Functions. Deploy the application on Amazon EC2 instances. Use Step Functions to invoke the workflow steps on the EC2 instances.</p>",
          "<p>C. Build out the workflow in Amazon EventBridge. Use EventBridge to invoke AWS Lambda functions on a schedule to process the workflow steps.</p>",
          "<p>D. Build out the workflow in AWS Step Functions. Use Step Functions to create a state machine. Use the state machine to invoke AWS Lambda functions to process the workflow steps.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is moving its data management application to AWS. The company wants to transition to an event-driven architecture. The architecture needs to be more distributed and to use serverless concepts while performing the different aspects of the workflow. The company also wants to minimize operational overhead. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402031,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is designing the network for an online multi-player game. The game uses the UDP networking protocol and will be deployed in eight AWS Regions. The network architecture needs to minimize latency and packet loss to give end users a high-quality gaming experience. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Setup a transit gateway in each Region. Create inter-Region peering attachments between each transit gateway.</p>",
          "<p>B. Set up AWS Global Accelerator with UDP listeners and endpoint groups in each Region.</p>",
          "<p>C. Set up Amazon CloudFront with UDP turned on. Configure an origin in each Region.</p>",
          "<p>D. Set up a VPC peering mesh between each Region. Turn on UDP for each VPC.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is designing the network for an online multi-player game. The game uses the UDP networking protocol and will be deployed in eight AWS Regions. The network architecture needs to minimize latency and packet loss to give end users a high-quality gaming experience. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402032,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company hosts a three-tier web application on Amazon EC2 instances in a single Availability Zone. The web application uses a self-managed MySQL database that is hosted on an EC2 instance to store data in an Amazon Elastic Block Store (Amazon EBS) volume. The MySQL database currently uses a 1 TB Provisioned IOPS SSD (io2) EBS volume. The company expects traffic of 1,000 IOPS for both reads and writes at peak traffic. The company wants to minimize any disruptions, stabilize performance, and reduce costs while retaining the capacity for double the IOPS. The company wants to move the database tier to a fully managed solution that is highly available and fault tolerant. Which solution will meet these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with an io2 Block Express EBS volume.</p>",
          "<p>B. Use a Multi-AZ deployment of an Amazon RDS for MySQL DB instance with a General Purpose SSD (gp2) EBS volume.</p>",
          "<p>C. Use Amazon S3 Intelligent-Tiering access tiers.</p>",
          "<p>D. Use two large EC2 instances to host the database in active-passive mode.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company hosts a three-tier web application on Amazon EC2 instances in a single Availability Zone. The web application uses a self-managed MySQL database that is hosted on an EC2 instance to store data in an Amazon Elastic Block Store (Amazon EBS) volume. The MySQL database currently uses a 1 TB Provisioned IOPS SSD (io2) EBS volume. The company expects traffic of 1,000 IOPS for both reads and writes at peak traffic. The company wants to minimize any disruptions, stabilize performance, and reduce costs while retaining the capacity for double the IOPS. The company wants to move the database tier to a fully managed solution that is highly available and fault tolerant. Which solution will meet these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402033,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company hosts a serverless application on AWS. The application uses Amazon API Gateway, AWS Lambda, and an Amazon RDS for PostgreSQL database. The company notices an increase in application errors that result from database connection timeouts during times of peak traffic or unpredictable traffic. The company needs a solution that reduces the application failures with the least amount of change to the code. What should a solutions architect do to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Enable RDS Proxy on the RDS DB instance.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Reduce the Lambda concurrency rate.</p>",
          "<p>B. Enable RDS Proxy on the RDS DB instance.</p>",
          "<p>C. Resize the RDS DB instance class to accept more connections.</p>",
          "<p>D. Migrate the database to Amazon DynamoDB with on-demand scaling.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company hosts a serverless application on AWS. The application uses Amazon API Gateway, AWS Lambda, and an Amazon RDS for PostgreSQL database. The company notices an increase in application errors that result from database connection timeouts during times of peak traffic or unpredictable traffic. The company needs a solution that reduces the application failures with the least amount of change to the code. What should a solutions architect do to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402034,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory. Which solution will run the batch job within 15 minutes with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Use AWS Batch on Amazon EC2.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use AWS Lambda with functional scaling.</p>",
          "<p>B. Use Amazon Elastic Container Service (Amazon ECS) with AWS Fargate.</p>",
          "<p>C. Use Amazon Lightsail with AWS Auto Scaling.</p>",
          "<p>D. Use AWS Batch on Amazon EC2.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is migrating an old application to AWS. The application runs a batch job every hour and is CPU intensive. The batch job takes 15 minutes on average with an on-premises server. The server has 64 virtual CPU (vCPU) and 512 GiB of memory. Which solution will run the batch job within 15 minutes with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402035,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company stores its data objects in Amazon S3 Standard storage. A solutions architect has found that 75% of the data is rarely accessed after 30 days. The company needs all the data to remain immediately accessible with the same high availability and resiliency, but the company wants to minimize storage costs. Which storage solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Move the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Move the data objects to S3 Glacier Deep Archive after 30 days.</p>",
          "<p>B. Move the data objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days.</p>",
          "<p>C. Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days.</p>",
          "<p>D. Move the data objects to S3 One Zone-Infrequent Access (S3 One Zone-IA) immediately.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company stores its data objects in Amazon S3 Standard storage. A solutions architect has found that 75% of the data is rarely accessed after 30 days. The company needs all the data to remain immediately accessible with the same high availability and resiliency, but the company wants to minimize storage costs. Which storage solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402036,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A gaming company is moving its public scoreboard from a data center to the AWS Cloud. The company uses Amazon EC2 Windows Server instances behind an Application Load Balancer to host its dynamic application. The company needs a highly available storage solution for the application. The application consists of static files and dynamic server-side code. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Store the static files on Amazon S3. Use Amazon CloudFront to cache objects at the edge.</p>",
          "<p>B. Store the static files on Amazon S3. Use Amazon ElastiCache to cache objects at the edge.</p>",
          "<p>C. Store the server-side code on Amazon Elastic File System (Amazon EFS). Mount the EFS volume on each EC2 instance to share the files.</p>",
          "<p>D. Store the server-side code on Amazon FSx for Windows File Server. Mount the FSx for Windows File Server volume on each EC2 instance to share the files. E. Store the server-side code on a General Purpose SSD (gp2) Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume on each EC2 instance to share the files.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A gaming company is moving its public scoreboard from a data center to the AWS Cloud. The company uses Amazon EC2 Windows Server instances behind an Application Load Balancer to host its dynamic application. The company needs a highly available storage solution for the application. The application consists of static files and dynamic server-side code. Which combination of steps should a solutions architect take to meet these requirements? (Choose two.)",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402037,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A social media company runs its application on Amazon EC2 instances behind an Application Load Balancer (ALB). The ALB is the origin for an Amazon CloudFront distribution. The application has more than a billion images stored in an Amazon S3 bucket and processes thousands of images each second. The company wants to resize the images dynamically and serve appropriate formats to clients. Which solution will meet these requirements with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviors that serve the images.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Install an external image management library on an EC2 instance. Use the image management library to process the images.</p>",
          "<p>B. Create a CloudFront origin request policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.</p>",
          "<p>C. Use a Lambda@Edge function with an external image management library. Associate the Lambda@Edge function with the CloudFront behaviors that serve the images.</p>",
          "<p>D. Create a CloudFront response headers policy. Use the policy to automatically resize images and to serve the appropriate format based on the User-Agent HTTP header in the request.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A social media company runs its application on Amazon EC2 instances behind an Application Load Balancer (ALB). The ALB is the origin for an Amazon CloudFront distribution. The application has more than a billion images stored in an Amazon S3 bucket and processes thousands of images each second. The company wants to resize the images dynamically and serve appropriate formats to clients. Which solution will meet these requirements with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402038,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A hospital needs to store patient records in an Amazon S3 bucket. The hospital’s compliance team must ensure that all protected health information (PHI) is encrypted in transit and at rest. The compliance team must administer the encryption key for data at rest. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create a public SSL/TLS certificate in AWS Certificate Manager (ACM). Associate the certificate with Amazon S3. Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.</p>",
          "<p>B. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with S3 managed encryption keys (SSE-S3). Assign the compliance team to manage the SSE-S3 keys.</p>",
          "<p>C. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Configure default encryption for each S3 bucket to use server-side encryption with AWS KMS keys (SSE-KMS). Assign the compliance team to manage the KMS keys.</p>",
          "<p>D. Use the aws:SecureTransport condition on S3 bucket policies to allow only encrypted connections over HTTPS (TLS). Use Amazon Macie to protect the sensitive data that is stored in Amazon S3. Assign the compliance team to manage Macie.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A hospital needs to store patient records in an Amazon S3 bucket. The hospital’s compliance team must ensure that all protected health information (PHI) is encrypted in transit and at rest. The compliance team must administer the encryption key for data at rest. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402039,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company uses Amazon API Gateway to run a private gateway with two REST APIs in the same VPC. The BuyStock RESTful web service calls the CheckFunds RESTful web service to ensure that enough funds are available before a stock can be purchased. The company has noticed in the VPC flow logs that the BuyStock RESTful web service calls the CheckFunds RESTful web service over the internet instead of through the VPC. A solutions architect must implement a solution so that the APIs communicate through the VPC. Which solution will meet these requirements with the FEWEST changes to the code?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Use an interface endpoint.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Add an X-API-Key header in the HTTP header for authorization.</p>",
          "<p>B. Use an interface endpoint.</p>",
          "<p>C. Use a gateway endpoint.</p>",
          "<p>D. Add an Amazon Simple Queue Service (Amazon SQS) queue between the two REST APIs.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company uses Amazon API Gateway to run a private gateway with two REST APIs in the same VPC. The BuyStock RESTful web service calls the CheckFunds RESTful web service to ensure that enough funds are available before a stock can be purchased. The company has noticed in the VPC flow logs that the BuyStock RESTful web service calls the CheckFunds RESTful web service over the internet instead of through the VPC. A solutions architect must implement a solution so that the APIs communicate through the VPC. Which solution will meet these requirements with the FEWEST changes to the code?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402040,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company hosts a multiplayer gaming application on AWS. The company wants the application to read data with sub-millisecond latency and run one-time queries on historical data. Which solution will meet these requirements with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use Amazon RDS for data that is frequently accessed. Run a periodic custom script to export the data to an Amazon S3 bucket.</p>",
          "<p>B. Store the data directly in an Amazon S3 bucket. Implement an S3 Lifecycle policy to move older data to S3 Glacier Deep Archive for longterm storage. Run one-time queries on the data in Amazon S3 by using Amazon Athena.</p>",
          "<p>C. Use Amazon DynamoDB with DynamoDB Accelerator (DAX) for data that is frequently accessed. Export the data to an Amazon S3 bucket by using DynamoDB table export. Run one-time queries on the data in Amazon S3 by using Amazon Athena.</p>",
          "<p>D. Use Amazon DynamoDB for data that is frequently accessed. Turn on streaming to Amazon Kinesis Data Streams. Use Amazon Kinesis Data Firehose to read the data from Kinesis Data Streams. Store the records in an Amazon S3 bucket.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company hosts a multiplayer gaming application on AWS. The company wants the application to read data with sub-millisecond latency and run one-time queries on historical data. Which solution will meet these requirements with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402041,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent. Otherwise, the payments might be processed incorrectly. Which actions should a solutions architect take to meet this requirement? (Choose two.)</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Write the messages to an Amazon DynamoDB table with the payment ID as the partition key.</p>",
          "<p>B. Write the messages to an Amazon Kinesis data stream with the payment ID as the partition key.</p>",
          "<p>C. Write the messages to an Amazon ElastiCache for Memcached cluster with the payment ID as the key.</p>",
          "<p>D. Write the messages to an Amazon Simple Queue Service (Amazon SQS) queue. Set the message attribute to use the payment ID. E. Write the messages to an Amazon Simple Queue Service (Amazon SQS) FIFO queue. Set the message group to use the payment ID.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company uses a payment processing system that requires messages for a particular payment ID to be received in the same order that they were sent. Otherwise, the payments might be processed incorrectly. Which actions should a solutions architect take to meet this requirement? (Choose two.)",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402042,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is building a game system that needs to send unique events to separate leaderboard, matchmaking, and authentication services concurrently. The company needs an AWS event-driven system that guarantees the order of the events. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Amazon Simple Notification Service (Amazon SNS) FIFO topics</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Amazon EventBridge event bus</p>",
          "<p>B. Amazon Simple Notification Service (Amazon SNS) FIFO topics</p>",
          "<p>C. Amazon Simple Notification Service (Amazon SNS) standard topics</p>",
          "<p>D. Amazon Simple Queue Service (Amazon SQS) FIFO queues</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is building a game system that needs to send unique events to separate leaderboard, matchmaking, and authentication services concurrently. The company needs an AWS event-driven system that guarantees the order of the events. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402043,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A hospital is designing a new application that gathers symptoms from patients. The hospital has decided to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) in the architecture. A solutions architect is reviewing the infrastructure design. Data must be encrypted at rest and in transit. Only authorized personnel of the hospital should be able to access the data. Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Turn on server-side encryption on the SQS components. Update the default key policy to restrict key usage to a set of authorized principals.</p>",
          "<p>B. Turn on server-side encryption on the SNS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals.</p>",
          "<p>C. Turn on encryption on the SNS components. Update the default key policy to restrict key usage to a set of authorized principals. Set a condition in the topic policy to allow only encrypted connections over TLS.</p>",
          "<p>D. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply a key policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS. E. Turn on server-side encryption on the SQS components by using an AWS Key Management Service (AWS KMS) customer managed key. Apply an IAM policy to restrict key usage to a set of authorized principals. Set a condition in the queue policy to allow only encrypted connections over TLS.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A hospital is designing a new application that gathers symptoms from patients. The hospital has decided to use Amazon Simple Queue Service (Amazon SQS) and Amazon Simple Notification Service (Amazon SNS) in the architecture. A solutions architect is reviewing the infrastructure design. Data must be encrypted at rest and in transit. Only authorized personnel of the hospital should be able to access the data. Which combination of steps should the solutions architect take to meet these requirements? (Choose two.)",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402044,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company runs a web application that is backed by Amazon RDS. A new database administrator caused data loss by accidentally editing information in a database table. To help recover from this type of incident, the company wants the ability to restore the database to its state from 5 minutes before any change within the last 30 days. Which feature should the solutions architect include in the design to meet this requirement?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Automated backups</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Read replicas</p>",
          "<p>B. Manual snapshots</p>",
          "<p>C. Automated backups</p>",
          "<p>D. Multi-AZ deployments</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company runs a web application that is backed by Amazon RDS. A new database administrator caused data loss by accidentally editing information in a database table. To help recover from this type of incident, the company wants the ability to restore the database to its state from 5 minutes before any change within the last 30 days. Which feature should the solutions architect include in the design to meet this requirement?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402045,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is using Amazon Route 53 latency-based routing to route requests to its UDP-based application for users around the world. The application is hosted on redundant servers in the company's on-premises data centers in the United States, Asia, and Europe. The company’s compliance requirements state that the application must be hosted on premises. The company wants to improve the performance and availability of the application. What should a solutions architect do to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the NLBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.</p>",
          "<p>B. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. Create an accelerator by using AWS Global Accelerator, and register the ALBs as its endpoints. Provide access to the application by using a CNAME that points to the accelerator DNS.</p>",
          "<p>C. Configure three Network Load Balancers (NLBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three NLBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.</p>",
          "<p>D. Configure three Application Load Balancers (ALBs) in the three AWS Regions to address the on-premises endpoints. In Route 53, create a latency-based record that points to the three ALBs, and use it as an origin for an Amazon CloudFront distribution. Provide access to the application by using a CNAME that points to the CloudFront DNS.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is using Amazon Route 53 latency-based routing to route requests to its UDP-based application for users around the world. The application is hosted on redundant servers in the company's on-premises data centers in the United States, Asia, and Europe. The company’s compliance requirements state that the application must be hosted on premises. The company wants to improve the performance and availability of the application. What should a solutions architect do to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402046,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords. What should the solutions architect do to accomplish this?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Set an overall password policy for the entire AWS account.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Set an overall password policy for the entire AWS account.</p>",
          "<p>B. Set a password policy for each IAM user in the AWS account.</p>",
          "<p>C. Use third-party vendor software to set password requirements.</p>",
          "<p>D. Attach an Amazon CloudWatch rule to the Create_newuser event to set the password with the appropriate requirements.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A solutions architect wants all new users to have specific complexity requirements and mandatory rotation periods for IAM user passwords. What should the solutions architect do to accomplish this?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402047,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has migrated an application to Amazon EC2 Linux instances. One of these EC2 instances runs several 1-hour tasks on a schedule. These tasks were written by different teams and have no common programming language. The company is concerned about performance and scalability while these tasks run on a single instance. A solutions architect needs to implement a solution to resolve these concerns. Which solution will meet these requirements with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use AWS Batch to run the tasks as jobs. Schedule the jobs by using Amazon EventBridge (Amazon CloudWatch Events).</p>",
          "<p>B. Convert the EC2 instance to a container. Use AWS App Runner to create the container on demand to run the tasks as jobs.</p>",
          "<p>C. Copy the tasks into AWS Lambda functions. Schedule the Lambda functions by using Amazon EventBridge (Amazon CloudWatch Events).</p>",
          "<p>D. Create an Amazon Machine Image (AMI) of the EC2 instance that runs the tasks. Create an Auto Scaling group with the AMI to run multiple copies of the instance.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has migrated an application to Amazon EC2 Linux instances. One of these EC2 instances runs several 1-hour tasks on a schedule. These tasks were written by different teams and have no common programming language. The company is concerned about performance and scalability while these tasks run on a single instance. A solutions architect needs to implement a solution to resolve these concerns. Which solution will meet these requirements with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402048,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company runs a public three-tier web application in a VPC. The application runs on Amazon EC2 instances across multiple Availability Zones. The EC2 instances that run in private subnets need to communicate with a license server over the internet. The company needs a managed solution that minimizes operational maintenance. Which solution meets these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Provision a NAT gateway in a public subnet. Modify each private subnet's route table with a default route that points to the NAT gateway.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Provision a NAT instance in a public subnet. Modify each private subnet's route table with a default route that points to the NAT instance.</p>",
          "<p>B. Provision a NAT instance in a private subnet. Modify each private subnet's route table with a default route that points to the NAT instance.</p>",
          "<p>C. Provision a NAT gateway in a public subnet. Modify each private subnet's route table with a default route that points to the NAT gateway.</p>",
          "<p>D. Provision a NAT gateway in a private subnet. Modify each private subnet's route table with a default route that points to the NAT gateway.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company runs a public three-tier web application in a VPC. The application runs on Amazon EC2 instances across multiple Availability Zones. The EC2 instances that run in private subnets need to communicate with a license server over the internet. The company needs a managed solution that minimizes operational maintenance. Which solution meets these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402049,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company needs to create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host a digital media streaming application. The EKS cluster will use a managed node group that is backed by Amazon Elastic Block Store (Amazon EBS) volumes for storage. The company must encrypt all data at rest by using a customer managed key that is stored in AWS Key Management Service (AWS KMS). Which combination of actions will meet this requirement with the LEAST operational overhead? (Choose two.)</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use a Kubernetes plugin that uses the customer managed key to perform data encryption.</p>",
          "<p>B. After creation of the EKS cluster, locate the EBS volumes. Enable encryption by using the customer managed key.</p>",
          "<p>C. Enable EBS encryption by default in the AWS Region where the EKS cluster will be created. Select the customer managed key as the default key.</p>",
          "<p>D. Create the EKS cluster. Create an IAM role that has a policy that grants permission to the customer managed key. Associate the role with the EKS cluster. E. Store the customer managed key as a Kubernetes secret in the EKS cluster. Use the customer managed key to encrypt the EBS volumes.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company needs to create an Amazon Elastic Kubernetes Service (Amazon EKS) cluster to host a digital media streaming application. The EKS cluster will use a managed node group that is backed by Amazon Elastic Block Store (Amazon EBS) volumes for storage. The company must encrypt all data at rest by using a customer managed key that is stored in AWS Key Management Service (AWS KMS). Which combination of actions will meet this requirement with the LEAST operational overhead? (Choose two.)",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402050,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code. When a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events. Which solution meets these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Store the images and geographic codes in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.</p>",
          "<p>B. Store the images in Amazon S3 buckets. Use Amazon DynamoDB with the geographic code as the key and the image S3 URL as the value.</p>",
          "<p>C. Store the images and geographic codes in an Amazon DynamoDB table. Configure DynamoDB Accelerator (DAX) during times of high load.</p>",
          "<p>D. Store the images in Amazon S3 buckets. Store geographic codes and image S3 URLs in a database table. Use Oracle running on an Amazon RDS Multi-AZ DB instance.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company wants to migrate an Oracle database to AWS. The database consists of a single table that contains millions of geographic information systems (GIS) images that are high resolution and are identified by a geographic code. When a natural disaster occurs, tens of thousands of images get updated every few minutes. Each geographic code has a single image or row that is associated with it. The company wants a solution that is highly available and scalable during such events. Which solution meets these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402051,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has an application that collects data from IoT sensors on automobiles. The data is streamed and stored in Amazon S3 through Amazon Kinesis Data Firehose. The data produces trillions of S3 objects each year. Each morning, the company uses the data from the previous 30 days to retrain a suite of machine learning (ML) models. Four times each year, the company uses the data from the previous 12 months to perform analysis and train other ML models. The data must be available with minimal delay for up to 1 year. After 1 year, the data must be retained for archival purposes. Which storage solution meets these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use the S3 Intelligent-Tiering storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.</p>",
          "<p>B. Use the S3 Intelligent-Tiering storage class. Configure S3 Intelligent-Tiering to automatically move objects to S3 Glacier Deep Archive after 1 year.</p>",
          "<p>C. Use the S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create an S3 Lifecycle policy to transition objects to S3 Glacier Deep Archive after 1 year.</p>",
          "<p>D. Use the S3 Standard storage class. Create an S3 Lifecycle policy to transition objects to S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days, and then to S3 Glacier Deep Archive after 1 year.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has an application that collects data from IoT sensors on automobiles. The data is streamed and stored in Amazon S3 through Amazon Kinesis Data Firehose. The data produces trillions of S3 objects each year. Each morning, the company uses the data from the previous 30 days to retrain a suite of machine learning (ML) models. Four times each year, the company uses the data from the previous 12 months to perform analysis and train other ML models. The data must be available with minimal delay for up to 1 year. After 1 year, the data must be retained for archival purposes. Which storage solution meets these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402052,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is running several business applications in three separate VPCs within the us-east-1 Region. The applications must be able to communicate between VPCs. The applications also must be able to consistently send hundreds of gigabytes of data each day to a latencysensitive application that runs in a single on-premises data center. A solutions architect needs to design a network connectivity solution that maximizes cost-effectiveness. Which solution meets these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Configure three AWS Site-to-Site VPN connections from the data center to AWS. Establish connectivity by configuring one VPN connection for each VPC.</p>",
          "<p>B. Launch a third-party virtual network appliance in each VPC. Establish an IPsec VPN tunnel between the data center and each virtual appliance.</p>",
          "<p>C. Set up three AWS Direct Connect connections from the data center to a Direct Connect gateway in us-east-1. Establish connectivity by configuring each VPC to use one of the Direct Connect connections.</p>",
          "<p>D. Set up one AWS Direct Connect connection from the data center to AWS. Create a transit gateway, and attach each VPC to the transit gateway. Establish connectivity between the Direct Connect connection and the transit gateway.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is running several business applications in three separate VPCs within the us-east-1 Region. The applications must be able to communicate between VPCs. The applications also must be able to consistently send hundreds of gigabytes of data each day to a latencysensitive application that runs in a single on-premises data center. A solutions architect needs to design a network connectivity solution that maximizes cost-effectiveness. Which solution meets these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402053,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>An ecommerce company is building a distributed application that involves several serverless functions and AWS services to complete orderprocessing tasks. These tasks require manual approvals as part of the workflow. A solutions architect needs to design an architecture for the order-processing application. The solution must be able to combine multiple AWS Lambda functions into responsive serverless applications. The solution also must orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers. Which solution will meet these requirements with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Use AWS Step Functions to build the application.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use AWS Step Functions to build the application.</p>",
          "<p>B. Integrate all the application components in an AWS Glue job.</p>",
          "<p>C. Use Amazon Simple Queue Service (Amazon SQS) to build the application.</p>",
          "<p>D. Use AWS Lambda functions and Amazon EventBridge events to build the application.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "An ecommerce company is building a distributed application that involves several serverless functions and AWS services to complete orderprocessing tasks. These tasks require manual approvals as part of the workflow. A solutions architect needs to design an architecture for the order-processing application. The solution must be able to combine multiple AWS Lambda functions into responsive serverless applications. The solution also must orchestrate data and services that run on Amazon EC2 instances, containers, or on-premises servers. Which solution will meet these requirements with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402054,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has launched an Amazon RDS for MySQL DB instance. Most of the connections to the database come from serverless applications. Application traffic to the database changes significantly at random intervals. At times of high demand, users report that their applications experience database connection rejection errors. Which solution will resolve this issue with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Create a proxy in RDS Proxy. Configure the users’ applications to use the DB instance through RDS Proxy.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create a proxy in RDS Proxy. Configure the users’ applications to use the DB instance through RDS Proxy.</p>",
          "<p>B. Deploy Amazon ElastiCache for Memcached between the users’ applications and the DB instance.</p>",
          "<p>C. Migrate the DB instance to a different instance class that has higher I/O capacity. Configure the users’ applications to use the new DB instance.</p>",
          "<p>D. Configure Multi-AZ for the DB instance. Configure the users’ applications to switch between the DB instances.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has launched an Amazon RDS for MySQL DB instance. Most of the connections to the database come from serverless applications. Application traffic to the database changes significantly at random intervals. At times of high demand, users report that their applications experience database connection rejection errors. Which solution will resolve this issue with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402055,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated. Which solution achieves these goals MOST efficiently?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use a scheduled AWS Lambda function and run a script remotely on all EC2 instances to send data to the audit system.</p>",
          "<p>B. Use EC2 Auto Scaling lifecycle hooks to run a custom script to send data to the audit system when instances are launched and terminated.</p>",
          "<p>C. Use an EC2 Auto Scaling launch configuration to run a custom script through user data to send data to the audit system when instances are launched and terminated.</p>",
          "<p>D. Run a custom script on the instance operating system to send data to the audit system. Configure the script to be invoked by the EC2 Auto Scaling group when the instance starts and is terminated.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated. Which solution achieves these goals MOST efficiently?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402056,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is developing a real-time multiplayer game that uses UDP for communications between the client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention. Which solution should a solutions architect recommend?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage.</p>",
          "<p>B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage.</p>",
          "<p>C. Use a Network Load Balancer for traffic distribution and Amazon Aurora Global Database for data storage.</p>",
          "<p>D. Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is developing a real-time multiplayer game that uses UDP for communications between the client and servers in an Auto Scaling group. Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention. Which solution should a solutions architect recommend?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402057,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company hosts a frontend application that uses an Amazon API Gateway API backend that is integrated with AWS Lambda. When the API receives requests, the Lambda function loads many libraries. Then the Lambda function connects to an Amazon RDS database, processes the data, and returns the data to the frontend application. The company wants to ensure that response latency is as low as possible for all its users with the fewest number of changes to the company's operations. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Configure provisioned concurrency for the Lambda function that handles the requests.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Establish a connection between the frontend application and the database to make queries faster by bypassing the API.</p>",
          "<p>B. Configure provisioned concurrency for the Lambda function that handles the requests.</p>",
          "<p>C. Cache the results of the queries in Amazon S3 for faster retrieval of similar datasets.</p>",
          "<p>D. Increase the size of the database to increase the number of connections Lambda can establish at one time.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company hosts a frontend application that uses an Amazon API Gateway API backend that is integrated with AWS Lambda. When the API receives requests, the Lambda function loads many libraries. Then the Lambda function connects to an Amazon RDS database, processes the data, and returns the data to the frontend application. The company wants to ensure that response latency is as low as possible for all its users with the fewest number of changes to the company's operations. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402058,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Scale the EC2 instances by using elastic resize. Scale the DB instances to zero outside of business hours.</p>",
          "<p>B. Explore AWS Marketplace for partner solutions that will automatically start and stop the EC2 instances and DB instances on a schedule.</p>",
          "<p>C. Launch another EC2 instance. Configure a crontab schedule to run shell scripts that will start and stop the existing EC2 instances and DB instances on a schedule.</p>",
          "<p>D. Create an AWS Lambda function that will start and stop the EC2 instances and DB instances. Configure Amazon EventBridge to invoke the Lambda function on a schedule.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is migrating its on-premises workload to the AWS Cloud. The company already uses several Amazon EC2 instances and Amazon RDS DB instances. The company wants a solution that automatically starts and stops the EC2 instances and DB instances outside of business hours. The solution must minimize cost and infrastructure maintenance. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402059,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company hosts a three-tier web application that includes a PostgreSQL database. The database stores the metadata from documents. The company searches the metadata for key terms to retrieve documents that the company reviews in a report each month. The documents are stored in Amazon S3. The documents are usually written only once, but they are updated frequently. The reporting process takes a few hours with the use of relational queries. The reporting process must not prevent any document modifications or the addition of new documents. A solutions architect needs to implement a solution to speed up the reporting process. Which solution will meet these requirements with the LEAST amount of change to the application code?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Set up a new Amazon DocumentDB (with MongoDB compatibility) cluster that includes a read replica. Scale the read replica to generate the reports.</p>",
          "<p>B. Set up a new Amazon Aurora PostgreSQL DB cluster that includes an Aurora Replica. Issue queries to the Aurora Replica to generate the reports.</p>",
          "<p>C. Set up a new Amazon RDS for PostgreSQL Multi-AZ DB instance. Configure the reporting module to query the secondary RDS node so that the reporting module does not affect the primary node.</p>",
          "<p>D. Set up a new Amazon DynamoDB table to store the documents. Use a fixed write capacity to support new document entries. Automatically scale the read capacity to support the reports.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company hosts a three-tier web application that includes a PostgreSQL database. The database stores the metadata from documents. The company searches the metadata for key terms to retrieve documents that the company reviews in a report each month. The documents are stored in Amazon S3. The documents are usually written only once, but they are updated frequently. The reporting process takes a few hours with the use of relational queries. The reporting process must not prevent any document modifications or the addition of new documents. A solutions architect needs to implement a solution to speed up the reporting process. Which solution will meet these requirements with the LEAST amount of change to the application code?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402060,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has a three-tier application on AWS that ingests sensor data from its users’ devices. The traffic flows through a Network Load Balancer (NLB), then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier. The application tier makes calls to a database. What should a solutions architect do to improve the security of the data in transit?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Configure a TLS listener. Deploy the server certificate on the NLB.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Configure a TLS listener. Deploy the server certificate on the NLB.</p>",
          "<p>B. Configure AWS Shield Advanced. Enable AWS WAF on the NLB.</p>",
          "<p>C. Change the load balancer to an Application Load Balancer (ALB). Enable AWS WAF on the ALB.</p>",
          "<p>D. Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances by using AWS Key Management Service (AWS KMS).</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has a three-tier application on AWS that ingests sensor data from its users’ devices. The traffic flows through a Network Load Balancer (NLB), then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier. The application tier makes calls to a database. What should a solutions architect do to improve the security of the data in transit?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402061,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is planning to migrate a commercial off-the-shelf application from its on-premises data center to AWS. The software has a software licensing model using sockets and cores with predictable capacity and uptime requirements. The company wants to use its existing licenses, which were purchased earlier this year. Which Amazon EC2 pricing option is the MOST cost-effective?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Dedicated Reserved Hosts</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Dedicated Reserved Hosts</p>",
          "<p>B. Dedicated On-Demand Hosts</p>",
          "<p>C. Dedicated Reserved Instances</p>",
          "<p>D. Dedicated On-Demand Instances</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is planning to migrate a commercial off-the-shelf application from its on-premises data center to AWS. The software has a software licensing model using sockets and cores with predictable capacity and uptime requirements. The company wants to use its existing licenses, which were purchased earlier this year. Which Amazon EC2 pricing option is the MOST cost-effective?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402062,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company runs an application on Amazon EC2 Linux instances across multiple Availability Zones. The application needs a storage layer that is highly available and Portable Operating System Interface (POSIX)-compliant. The storage layer must provide maximum data durability and must be shareable across the EC2 instances. The data in the storage layer will be accessed frequently for the first 30 days and will be accessed infrequently after that time. Which solution will meet these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Glacier.</p>",
          "<p>B. Use the Amazon S3 Standard storage class. Create an S3 Lifecycle policy to move infrequently accessed data to S3 Standard-Infrequent Access (S3 Standard-IA).</p>",
          "<p>C. Use the Amazon Elastic File System (Amazon EFS) Standard storage class. Create a lifecycle management policy to move infrequently accessed data to EFS Standard-Infrequent Access (EFS Standard-IA).</p>",
          "<p>D. Use the Amazon Elastic File System (Amazon EFS) One Zone storage class. Create a lifecycle management policy to move infrequently accessed data to EFS One Zone-Infrequent Access (EFS One Zone-IA).</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company runs an application on Amazon EC2 Linux instances across multiple Availability Zones. The application needs a storage layer that is highly available and Portable Operating System Interface (POSIX)-compliant. The storage layer must provide maximum data durability and must be shareable across the EC2 instances. The data in the storage layer will be accessed frequently for the first 30 days and will be accessed infrequently after that time. Which solution will meet these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402063,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A solutions architect is creating a new VPC design. There are two public subnets for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web servers use only HTTPS. The solutions architect has already created a security group for the load balancer allowing port 443 from 0.0.0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks. Which additional configuration strategy should the solutions architect use to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create a security group for the web servers and allow port 443 from 0.0.0.0/0. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.</p>",
          "<p>B. Create a network ACL for the web servers and allow port 443 from 0.0.0.0/0. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.</p>",
          "<p>C. Create a security group for the web servers and allow port 443 from the load balancer. Create a security group for the MySQL servers and allow port 3306 from the web servers security group.</p>",
          "<p>D. Create a network ACL for the web servers and allow port 443 from the load balancer. Create a network ACL for the MySQL servers and allow port 3306 from the web servers security group.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A solutions architect is creating a new VPC design. There are two public subnets for the load balancer, two private subnets for web servers, and two private subnets for MySQL. The web servers use only HTTPS. The solutions architect has already created a security group for the load balancer allowing port 443 from 0.0.0.0/0. Company policy requires that each resource has the least access required to still be able to perform its tasks. Which additional configuration strategy should the solutions architect use to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402064,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>An ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2, and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns. Which action should be taken to improve the performance of the backend?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Implement Amazon ElastiCache to cache the large datasets.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Implement Amazon SNS to store the database calls.</p>",
          "<p>B. Implement Amazon ElastiCache to cache the large datasets.</p>",
          "<p>C. Implement an RDS for MySQL read replica to cache database calls.</p>",
          "<p>D. Implement Amazon Kinesis Data Firehose to stream the calls to the database.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "An ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2, and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns. Which action should be taken to improve the performance of the backend?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402065,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege. Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.)</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Have the deployment engineer use AWS account root user credentials for performing AWS CloudFormation stack operations.</p>",
          "<p>B. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the PowerUsers IAM policy attached.</p>",
          "<p>C. Create a new IAM user for the deployment engineer and add the IAM user to a group that has the AdministratorAccess IAM policy attached.</p>",
          "<p>D. Create a new IAM user for the deployment engineer and add the IAM user to a group that has an IAM policy that allows AWS CloudFormation actions only. E. Create an IAM role for the deployment engineer to explicitly define the permissions specific to the AWS CloudFormation stack and launch stacks using that IAM role.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A new employee has joined a company as a deployment engineer. The deployment engineer will be using AWS CloudFormation templates to create multiple AWS resources. A solutions architect wants the deployment engineer to perform job activities while following the principle of least privilege. Which combination of actions should the solutions architect take to accomplish this goal? (Choose two.)",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402066,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is deploying a two-tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information. The web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs, security groups, and route tables are still in their default states. What should a solutions architect recommend to fix the application?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>D. Add an inbound rule to the security group of the database tier’s RDS instance to allow traffic from the web tiers security group.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Add an explicit rule to the private subnet’s network ACL to allow traffic from the web tier’s EC2 instances.</p>",
          "<p>B. Add a route in the VPC route table to allow traffic between the web tier’s EC2 instances and the database tier.</p>",
          "<p>C. Deploy the web tier's EC2 instances and the database tier’s RDS instance into two separate VPCs, and configure VPC peering.</p>",
          "<p>D. Add an inbound rule to the security group of the database tier’s RDS instance to allow traffic from the web tiers security group.</p>"
        ]
      },
      "correct_response": [
        "d"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is deploying a two-tier web application in a VPC. The web tier is using an Amazon EC2 Auto Scaling group with public subnets that span multiple Availability Zones. The database tier consists of an Amazon RDS for MySQL DB instance in separate private subnets. The web tier requires access to the database to retrieve product information. The web application is not working as intended. The web application reports that it cannot connect to the database. The database is confirmed to be up and running. All configurations for the network ACLs, security groups, and route tables are still in their default states. What should a solutions architect recommend to fix the application?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402067,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has a large dataset for its online advertising business stored in an Amazon RDS for MySQL DB instance in a single Availability Zone. The company wants business reporting queries to run without impacting the write operations to the production DB instance. Which solution meets these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Deploy RDS read replicas to process the business reporting queries.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Deploy RDS read replicas to process the business reporting queries.</p>",
          "<p>B. Scale out the DB instance horizontally by placing it behind an Elastic Load Balancer.</p>",
          "<p>C. Scale up the DB instance to a larger instance type to handle write operations and queries.</p>",
          "<p>D. Deploy the DB instance in multiple Availability Zones to process the business reporting queries.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has a large dataset for its online advertising business stored in an Amazon RDS for MySQL DB instance in a single Availability Zone. The company wants business reporting queries to run without impacting the write operations to the production DB instance. Which solution meets these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402068,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company’s recovery point objective (RPO) is 2 hours. The backup strategy must maximize scalability and optimize resource utilization for this environment. Which solution will meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances and database every 2 hours to meet the RPO.</p>",
          "<p>B. Configure a snapshot lifecycle policy to take Amazon Elastic Block Store (Amazon EBS) snapshots. Enable automated backups in Amazon RDS to meet the RPO.</p>",
          "<p>C. Retain the latest Amazon Machine Images (AMIs) of the web and application tiers. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.</p>",
          "<p>D. Take snapshots of Amazon Elastic Block Store (Amazon EBS) volumes of the EC2 instances every 2 hours. Enable automated backups in Amazon RDS and use point-in-time recovery to meet the RPO.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company needs a backup strategy for its three-tier stateless web application. The web application runs on Amazon EC2 instances in an Auto Scaling group with a dynamic scaling policy that is configured to respond to scaling events. The database tier runs on Amazon RDS for PostgreSQL. The web application does not require temporary local storage on the EC2 instances. The company’s recovery point objective (RPO) is 2 hours. The backup strategy must maximize scalability and optimize resource utilization for this environment. Which solution will meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402069,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company wants to deploy a new public web application on AWS. The application includes a web server tier that uses Amazon EC2 instances. The application also includes a database tier that uses an Amazon RDS for MySQL DB instance. The application must be secure and accessible for global customers that have dynamic IP addresses. How should a solutions architect configure the security groups to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers.</p>",
          "<p>B. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the security group of the web servers.</p>",
          "<p>C. Configure the security group for the web servers to allow inbound traffic on port 443 from the IP addresses of the customers. Configure the security group for the DB instance to allow inbound traffic on port 3306 from the IP addresses of the customers.</p>",
          "<p>D. Configure the security group for the web servers to allow inbound traffic on port 443 from 0.0.0.0/0. Configure the security group for the DB instance to allow inbound traffic on port 3306 from 0.0.0.0/0.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company wants to deploy a new public web application on AWS. The application includes a web server tier that uses Amazon EC2 instances. The application also includes a database tier that uses an Amazon RDS for MySQL DB instance. The application must be secure and accessible for global customers that have dynamic IP addresses. How should a solutions architect configure the security groups to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402070,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A payment processing company records all voice communication with its customers and stores the audio files in an Amazon S3 bucket. The company needs to capture the text from the audio files. The company must remove from the text any personally identifiable information (PII) that belongs to customers. What should a solutions architect do to meet these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Process the audio files by using Amazon Kinesis Video Streams. Use an AWS Lambda function to scan for known PII patterns.</p>",
          "<p>B. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start an Amazon Textract task to analyze the call recordings.</p>",
          "<p>C. Configure an Amazon Transcribe transcription job with PII redaction turned on. When an audio file is uploaded to the S3 bucket, invoke an AWS Lambda function to start the transcription job. Store the output in a separate S3 bucket.</p>",
          "<p>D. Create an Amazon Connect contact flow that ingests the audio files with transcription turned on. Embed an AWS Lambda function to scan for known PII patterns. Use Amazon EventBridge to start the contact flow when an audio file is uploaded to the S3 bucket.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A payment processing company records all voice communication with its customers and stores the audio files in an Amazon S3 bucket. The company needs to capture the text from the audio files. The company must remove from the text any personally identifiable information (PII) that belongs to customers. What should a solutions architect do to meet these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402071,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company is running a multi-tier ecommerce web application in the AWS Cloud. The application runs on Amazon EC2 instances with an Amazon RDS for MySQL Multi-AZ DB instance. Amazon RDS is configured with the latest generation DB instance with 2,000 GB of storage in a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. The database performance affects the application during periods of high demand. A database administrator analyzes the logs in Amazon CloudWatch Logs and discovers that the application performance always degrades when the number of read and write IOPS is higher than 20,000. What should a solutions architect do to improve the application performance?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Replace the volume with a Provisioned IOPS SSD (io2) volume.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Replace the volume with a magnetic volume.</p>",
          "<p>B. Increase the number of IOPS on the gp3 volume.</p>",
          "<p>C. Replace the volume with a Provisioned IOPS SSD (io2) volume.</p>",
          "<p>D. Replace the 2,000 GB gp3 volume with two 1,000 GB gp3 volumes.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company is running a multi-tier ecommerce web application in the AWS Cloud. The application runs on Amazon EC2 instances with an Amazon RDS for MySQL Multi-AZ DB instance. Amazon RDS is configured with the latest generation DB instance with 2,000 GB of storage in a General Purpose SSD (gp3) Amazon Elastic Block Store (Amazon EBS) volume. The database performance affects the application during periods of high demand. A database administrator analyzes the logs in Amazon CloudWatch Logs and discovers that the application performance always degrades when the number of read and write IOPS is higher than 20,000. What should a solutions architect do to improve the application performance?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402072,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>An IAM user made several configuration changes to AWS resources in their company's account during a production deployment last week. A solutions architect learned that a couple of security group rules are not configured as desired. The solutions architect wants to confirm which IAM user was responsible for making changes. Which service should the solutions architect use to find the desired information?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. AWS CloudTrail</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Amazon GuardDuty</p>",
          "<p>B. Amazon Inspector</p>",
          "<p>C. AWS CloudTrail</p>",
          "<p>D. AWS Config</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "An IAM user made several configuration changes to AWS resources in their company's account during a production deployment last week. A solutions architect learned that a couple of security group rules are not configured as desired. The solutions architect wants to confirm which IAM user was responsible for making changes. Which service should the solutions architect use to find the desired information?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402073,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company has implemented a self-managed DNS service on AWS. The solution consists of the following: • Amazon EC2 instances in different AWS Regions • Endpoints of a standard accelerator in AWS Global Accelerator The company wants to protect the solution against DDoS attacks. What should a solutions architect do to meet this requirement?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>A. Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Subscribe to AWS Shield Advanced. Add the accelerator as a resource to protect.</p>",
          "<p>B. Subscribe to AWS Shield Advanced. Add the EC2 instances as resources to protect.</p>",
          "<p>C. Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the accelerator.</p>",
          "<p>D. Create an AWS WAF web ACL that includes a rate-based rule. Associate the web ACL with the EC2 instances.</p>"
        ]
      },
      "correct_response": [
        "a"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company has implemented a self-managed DNS service on AWS. The solution consists of the following: • Amazon EC2 instances in different AWS Regions • Endpoints of a standard accelerator in AWS Global Accelerator The company wants to protect the solution against DDoS attacks. What should a solutions architect do to meet this requirement?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402074,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>An ecommerce company needs to run a scheduled daily job to aggregate and filter sales records for analytics. The company stores the sales records in an Amazon S3 bucket. Each object can be up to 10 GB in size. Based on the number of sales events, the job can take up to an hour to complete. The CPU and memory usage of the job are constant and are known in advance. A solutions architect needs to minimize the amount of operational effort that is needed for the job to run. Which solution meets these requirements?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create an AWS Lambda function that has an Amazon EventBridge notification. Schedule the EventBridge event to run once a day.</p>",
          "<p>B. Create an AWS Lambda function. Create an Amazon API Gateway HTTP API, and integrate the API with the function. Create an Amazon EventBridge scheduled event that calls the API and invokes the function.</p>",
          "<p>C. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an AWS Fargate launch type. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.</p>",
          "<p>D. Create an Amazon Elastic Container Service (Amazon ECS) cluster with an Amazon EC2 launch type and an Auto Scaling group with at least one EC2 instance. Create an Amazon EventBridge scheduled event that launches an ECS task on the cluster to run the job.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "An ecommerce company needs to run a scheduled daily job to aggregate and filter sales records for analytics. The company stores the sales records in an Amazon S3 bucket. Each object can be up to 10 GB in size. Based on the number of sales events, the job can take up to an hour to complete. The CPU and memory usage of the job are constant and are known in advance. A solutions architect needs to minimize the amount of operational effort that is needed for the job to run. Which solution meets these requirements?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402075,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A company needs to transfer 600 TB of data from its on-premises network-attached storage (NAS) system to the AWS Cloud. The data transfer must be complete within 2 weeks. The data is sensitive and must be encrypted in transit. The company’s internet connection can support an upload speed of 100 Mbps. Which solution meets these requirements MOST cost-effectively?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Use the AWS Snow Family console to order several AWS Snowball Edge Storage Optimized devices. Use the devices to transfer the data to Amazon S3.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use Amazon S3 multi-part upload functionality to transfer the files over HTTPS.</p>",
          "<p>B. Create a VPN connection between the on-premises NAS system and the nearest AWS Region. Transfer the data over the VPN connection.</p>",
          "<p>C. Use the AWS Snow Family console to order several AWS Snowball Edge Storage Optimized devices. Use the devices to transfer the data to Amazon S3.</p>",
          "<p>D. Set up a 10 Gbps AWS Direct Connect connection between the company location and the nearest AWS Region. Transfer the data over a VPN connection into the Region to store the data in Amazon S3.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A company needs to transfer 600 TB of data from its on-premises network-attached storage (NAS) system to the AWS Cloud. The data transfer must be complete within 2 weeks. The data is sensitive and must be encrypted in transit. The company’s internet connection can support an upload speed of 100 Mbps. Which solution meets these requirements MOST cost-effectively?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402076,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A financial company hosts a web application on AWS. The application uses an Amazon API Gateway Regional API endpoint to give users the ability to retrieve current stock prices. The company’s security team has noticed an increase in the number of API requests. The security team is concerned that HTTP flood attacks might take the application offline. A solutions architect must design a solution to protect the application from this type of attack. Which solution meets these requirements with the LEAST operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>B. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Create an Amazon CloudFront distribution in front of the API Gateway Regional API endpoint with a maximum TTL of 24 hours.</p>",
          "<p>B. Create a Regional AWS WAF web ACL with a rate-based rule. Associate the web ACL with the API Gateway stage.</p>",
          "<p>C. Use Amazon CloudWatch metrics to monitor the Count metric and alert the security team when the predefined rate is reached.</p>",
          "<p>D. Create an Amazon CloudFront distribution with Lambda@Edge in front of the API Gateway Regional API endpoint. Create an AWS Lambda function to block requests from IP addresses that exceed the predefined rate.</p>"
        ]
      },
      "correct_response": [
        "b"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A financial company hosts a web application on AWS. The application uses an Amazon API Gateway Regional API endpoint to give users the ability to retrieve current stock prices. The company’s security team has noticed an increase in the number of API requests. The security team is concerned that HTTP flood attacks might take the application offline. A solutions architect must design a solution to protect the application from this type of attack. Which solution meets these requirements with the LEAST operational overhead?",
      "related_lectures": []
    },
    {
      "_class": "assessment",
      "id": 113402077,
      "assessment_type": "multiple-choice",
      "prompt": {
        "question": "<p>A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application. What should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?</p>\n",
        "relatedLectureIds": "",
        "feedbacks": [
          "",
          "",
          "",
          ""
        ],
        "explanation": "<p>Correct answer: <strong>C. Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.</strong></p>\n\n<p>This is an AWS Certified Solutions Architect Associate SAA-C03 practice question.</p>",
        "answers": [
          "<p>A. Use DynamoDB transactions to write new event data to the table. Configure the transactions to notify internal teams.</p>",
          "<p>B. Have the current application publish a message to four Amazon Simple Notification Service (Amazon SNS) topics. Have each team subscribe to one topic.</p>",
          "<p>C. Enable Amazon DynamoDB Streams on the table. Use triggers to write to a single Amazon Simple Notification Service (Amazon SNS) topic to which the teams can subscribe.</p>",
          "<p>D. Add a custom attribute to each record to flag new items. Write a cron job that scans the table every minute for items that are new and notifies an Amazon Simple Queue Service (Amazon SQS) queue to which the teams can subscribe.</p>"
        ]
      },
      "correct_response": [
        "c"
      ],
      "section": "AWS Solutions Architect",
      "question_plain": "A meteorological startup company has a custom web application to sell weather data to its users online. The company uses Amazon DynamoDB to store its data and wants to build a new service that sends an alert to the managers of four internal teams every time a new weather event is recorded. The company does not want this new service to affect the performance of the current application. What should a solutions architect do to meet these requirements with the LEAST amount of operational overhead?",
      "related_lectures": []
    }
  ]
}